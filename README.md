# HBASE

## Введение

Apache HBase – это нереляционная, распределенная база данных с открытым исходным кодом, написанная на языке Java по аналогии BigTable от Google. Изначально эта СУБД класса NoSQL создавалась компанией Powerset в 2007 году для обработки больших объёмов данных в рамках поисковой системы на естественном языке. Проектом верхнего уровня Apache Software Foundation HBase стала в 2010 году. На данный момент стабильной актуальной версией является 2.4.11.

СУБД относится к категории wide-column store и представляет собой колоночно-ориентированное, мультиверсионное хранилище типа key-value. Она работает поверх распределенной файловой системы HDFS и обеспечивает возможности BigTable для Hadoop, реализуя отказоустойчивый способ хранения больших объёмов разреженных данных. 


## Факты

- нет вторичных индексов, нужно ставить доп. расширения
- нет транзакций, но есть lock-и на ряды и счетчики
- плохо подходит для нескольких датацентров
- как такового языка запросов нет, взаимодействие осуществляется через api. В основном, для удобства, используется еще одна прослойка над api - hbase shell, именно через него будет осуществляться взаимодействие


## Модель данных

Модель данных HBase реализуется по типу ключ-значение – <table, RowKey, Column Family, Column, timestamp> -> Value:

- данные организованы в таблицы, проиндексированные первичным ключом: RowKey;
- для каждого первичного ключа может храниться неограниченный набор атрибутов - колонок;
- колонки организованны в группы колонок (Column Family). Обычно в одну группу объединяют колонки с одинаковым шаблоном использования и хранения. Список и названия групп колонок фиксирован и имеет четкую схему. На уровне группы колонок задаются такие параметры как time to live (TTL) и максимальное количество хранимых версий;
- для каждого атрибута может храниться несколько различных версий. Разные версии имеют разный штамп времени (timestamp);
- записи физически хранятся в порядке, отсортированном по первичному ключу. При этом информация из разных колонок хранится отдельно, благодаря чему можно считывать данные только из нужного семейства колонок, тем самым, ускоряя операцию чтения;
- атрибуты, принадлежащие одной группе колонок и соответствующие одному ключу, физически хранятся как отсортированный список. Любой атрибут может отсутствовать или присутствовать для каждого ключа. Отсутствие атрибута не влечет никаких накладных расходов на хранение пустых значений;
- если разница между штампом времени (timestamp) для определенной версии и текущим временем больше TTL, такая запись помечается к удалению. Аналогично, если количество версий для определённого атрибута превысило максимальное количество версий.


### Пример

Рассмотрим как привычное многим представление переходит в колоночно-ориентированное:

![image](https://user-images.githubusercontent.com/45429125/166156233-970ecbd9-a171-4663-882c-a01035ee5190.png)


И обратно:

В данном случае имеется две ColumnFamily: data и meta. Первая содержит в себе колонку с именем "", а вторая - mimetype и size. Также у каждой записи в правом нижнем углу можно увидеть значения timestamp-ов.

![image](https://user-images.githubusercontent.com/45429125/166156243-db3b9965-7ead-4a3f-a38c-339b6251dada.png)

А так это будет выглядеть в виде, привычной многим, таблицы: (колонка Counters - служебная и не особо нам интересна на данном этапе)

![image](https://user-images.githubusercontent.com/45429125/166156686-d40c6adf-805d-479b-9316-4ab022a9f4ad.png)


## Архитектура

### Регионы
Распределение данных по разным физическим машинам кластера обеспечивается механизмом регионирования – автоматической горизонтальной группировки табличных строк. 

Регион — это диапазон записей, соответствующих определенному диапазону подряд идущих первичных ключей. Каждый регион характеризуется некоторым количеством файлов hdfs и обслуживается Region Server, который в свою очередь является HDFS DataNode.

Вот так выглядит физическое представление Region Server:

![image](https://user-images.githubusercontent.com/45429125/166157443-131b529b-b226-4fdf-b71e-48368da1958a.png)

Каждый регион содержит следующие параметры:

- Data Storage - основное хранилище данных в Hbase. Данные физически хранятся на HDFS, в специальном формате - HFile, отсортированные по значению первичного ключа (RowKey). Одной паре (region, column family) соответствует как минимум один HFIle;
- MemStore - буфер для запись, специально выделенная область памяти для накопления данных перед записью, поскольку обновлять каждую запись в отсортированном HFile довольно дорого. Как только MemStore наполнится до некоторого критического значения, создается очередной HFile, куда будут записаны новые данные. Один на ColumnFamily;
- BlockCache - кэш на чтение;
- Write Ahead Log (WAL) – файл для логгирования всех операций с данными, чтобы их можно было восстановить в случае сбоя. Является единственным для каждого RegionServer;


Для наглядности:

![image](https://user-images.githubusercontent.com/45429125/166157114-0da8914f-abf7-44a7-aaa5-072f1dff9cf8.png)


### Zookeeper, master and slave

Введем следующие понятия:

- Master Server - главный узел в кластере, управляющий распределением регионов по региональным серверам, включая ведение их реестра, управление запусками регулярных задач и других организационных действий;
- ZooKeeper - распределенный сервис синхронизаций. Подробнее c данным "зверем" можно ознакомится самостоятельно.

Итак, наша модель взаимодействия выглядит следующим образом: (Store == Column Family)

![image](https://user-images.githubusercontent.com/45429125/166157282-4ad77014-0a36-4818-ae14-388abf48fad0.png)


Рассмотрим подробнее, как происходит запись:

1. Client хочет записать некоторые данные. Чтобы понять куда писать, клиент обращается к zookeeper и получает адрес Root Region;
2. Client обращается к Root region и получает адрес нужного RegionServer из таблицы META;
3. Client обращается к этому серверу и производит запись:
    - производится запись в HLOG;
    - далее, запись в MemStore. Как только MemStore наполнится до некоторого критического значения, создается очередной HFile, куда будут записаны новые данные.

Изначально таблица состоит из одного региона, который разбивается на новые по мере роста (после превышения конкретно заданного порогового размера). Когда таблица становится слишком большой для одного сервера, она обслуживается кластером, на каждом узле которого размещается подмножество регионов таблицы. Таким образом, регионирование обеспечивает распределение нагрузки на таблицу. Совокупность отсортированных регионов, доступных по сети, образует общее содержимое распределенной таблицы.

Поскольку данные по одному региону могут храниться в нескольких HFile, для ускорения работы HBase периодически объединяет их, выполняя одну из 2-х операций под названием compaction:

- Minor Compaction, который запускается автоматически и выполняется в фоновом режиме. Имеет низкий приоритет по сравнению с другими операциями.
- Major Compaction, запускаемый вручную или в случае наступления определенных условий (триггеров), например, срабатывание по таймеру. Имеет высокий приоритет и может существенно замедлить работу кластера. Эту операцию рекомендуется выполнять при невысокой нагрузке на кластер. Во время выполнения Major Compaction также происходит физическое удаление данных, ранее помеченных соответствующей меткой tombstone.

![hbase_2](https://user-images.githubusercontent.com/45429125/166156934-7de5d18c-b586-453e-9823-0beac4346643.png)


## CRUD

- все операции происходят через объект Htable
- все операции атомарны отсительно ряда(Row)
- доступен Row Lock
- доступны Batch

### Put

Put – добавить новую или обновить существующую запись. Временной штамп (timestamp) этой записи может быть задан вручную или установлен автоматически как текущее время.
Для добавления новой записи используется инструкция

put ’<table name>’,’row1’,’<colfamily:colname>’,’<value>’
